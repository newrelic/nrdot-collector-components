# Adaptive Telemetry Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: traces, metrics, logs |
| Distributions | [nrdot] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/newrelic/nrdot-collector-components?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fadaptivetelemetry%20&label=open&color=orange&logo=opentelemetry)](https://github.com/newrelic/nrdot-collector-components/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fadaptivetelemetry) [![Closed issues](https://img.shields.io/github/issues-search/newrelic/nrdot-collector-components?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fadaptivetelemetry%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/newrelic/nrdot-collector-components/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fadaptivetelemetry) |
| [Code Owners](https://github.com/newrelic/nrdot-collector-components/blob/main/.github/CODEOWNERS)    | [@your-github-username] |

[development]: https://github.com/open-telemetry/opentelemetry-collector#development
[nrdot]: https://github.com/newrelic/nrdot-collector-releases
<!-- end autogenerated section -->

## Overview

The Adaptive Telemetry Processor (ATP) is an intelligent metric filtering and adaptive sampling component designed for the New Relic OpenTelemetry Collector. It dynamically monitors system and process metrics, filtering out low-value telemetry based on configurable thresholds while maintaining high observability during critical events. ATP reduces telemetry costs by up to 70% while preserving visibility into performance anomalies.

### Key Features

- **Metric Threshold Filtering**: Filters metrics based on configurable thresholds for CPU, memory, disk, and network
- **Process-Based Sampling**: Monitors specific processes by full path (e.g., `/usr/sbin/nginx`, `/usr/bin/java`)
- **Dynamic Threshold Adjustment**: Automatically adapts thresholds based on historical baselines and workload patterns
- **Multi-Metric Composite Scoring**: Combines multiple metrics with configurable weights for holistic health assessment
- **Anomaly Detection**: Detects sudden metric changes and ensures anomalous data is always captured
- **Stateful Processing**: Maintains persistent state in JSON file across collector restarts
- **Low Overhead**: Minimal performance impact with efficient metric evaluation

### Use Cases

- **Cost Optimization**: Reduce telemetry volume by 50-70% by filtering "normal" metrics while preserving anomalies
- **Noise Reduction**: Eliminate low-value metrics from idle or baseline systems
- **Selective Monitoring**: Monitor only specific processes (applications, containers, services)
- **Dynamic Environments**: Adapt to changing workload patterns in containerized or cloud environments
- **Performance Troubleshooting**: Automatically increase sampling during performance degradation
- **Compliance & Auditing**: Maintain complete audit trail during critical events while reducing steady-state data

## Configuration

### Basic Configuration

```yaml
processors:
  adaptivetelemetryprocessor:
    # Storage configuration for persistence (JSON file)
    # SECURITY: storage_path must be under /var/lib/nrdot-collector/
    storage_path: "/var/lib/nrdot-collector/adaptiveprocess.db"

    # Data retention period in minutes
    retention_minutes: 30

    # Process list to monitor
    # SECURITY: Use full paths in production to prevent spoofing
    include_process_list:
      - "/usr/sbin/nginx"        # Full path (recommended)
      - "/usr/bin/java"          # Full path (recommended)
      - "/usr/bin/postgres"      # Full path (recommended)
    
    # Metric thresholds - metrics below these values are filtered out
    metric_thresholds:
      # CPU metrics (utilization is 0-1 scale, time in seconds)
      system.cpu.utilization: 0.05           # 5% CPU utilization
      system.cpu.time: 5.0                   # 5 seconds CPU time
      
      # Memory metrics (utilization 0-1 scale, usage in bytes)
      system.memory.utilization: 0.05        # 5% memory utilization
      system.memory.usage: 104857600         # 100 MB
      
      # Process-specific metrics
      process.cpu.utilization: 0.05          # 5% process CPU
      process.memory.usage: 104857600        # 100 MB process memory
      
      # Disk metrics
      system.disk.io: 1048576                # 1 MB disk I/O
      system.filesystem.utilization: 0.05    # 5% disk utilization
      
      # Network metrics
      system.network.io: 1048576             # 1 MB network I/O
```

### Advanced Configuration

```yaml
processors:
  adaptivetelemetryprocessor:
    # Storage configuration
    # SECURITY: storage_path must be under /var/lib/nrdot-collector/
    storage_path: "/var/lib/nrdot-collector/adaptiveprocess.db"
    retention_minutes: 30
    
    # Process filtering - monitor specific processes
    # Use full paths for security (prevents process name spoofing)
    include_process_list:
      - "/usr/bin/stress-ng"
      - "/usr/sbin/nginx"
      - "/usr/bin/java"
      - "/usr/bin/postgres"
    
    # Static metric thresholds - metrics below these values are filtered
    metric_thresholds:
      # CPU metrics from hostmetrics receiver
      system.cpu.utilization: 0.05           # 5% CPU utilization (0-1 scale)
      system.cpu.time: 5.0                   # CPU time in seconds
      
      # Memory metrics from hostmetrics receiver
      system.memory.utilization: 0.05        # 5% memory utilization (0-1 scale)
      system.memory.usage: 100               # in bytes (minimal for testing)
      
      # Process metrics from hostmetrics receiver
      process.cpu.utilization: 0.05          # 5% process CPU (0-1 scale)
      process.memory.usage: 100              # process memory in bytes
      process.memory.virtual: 100            # virtual memory in bytes
      
      # Disk metrics from hostmetrics receiver
      system.disk.io.read_bytes: 100         # 100B disk read
      system.disk.io.write_bytes: 100        # 100B disk write
      system.filesystem.utilization: 0.05    # 5% disk utilization (0-1 scale)
      
      # Network metrics from hostmetrics receiver
      system.network.io.receive_bytes: 100   # 100B network receive
      system.network.io.transmit_bytes: 100  # 100B network transmit
    
    # Dynamic threshold configuration
    enable_dynamic_thresholds: true
    dynamic_smoothing_factor: 0.1            # Exponential moving average smoothing
    
    # Minimum thresholds (dynamic thresholds cannot go below these)
    min_thresholds:
      system.cpu.utilization: 0.04           # Minimum 4% CPU
      system.memory.utilization: 0.04        # Minimum 4% memory
      process.cpu.utilization: 0.04          # Minimum 4% process CPU
      system.filesystem.utilization: 0.04    # Minimum 4% disk
    
    # Maximum thresholds (dynamic thresholds cannot exceed these)
    max_thresholds:
      system.cpu.utilization: 0.30           # Maximum 30% CPU
      system.memory.utilization: 0.30        # Maximum 30% memory
      process.cpu.utilization: 0.30          # Maximum 30% process CPU
      system.filesystem.utilization: 0.30    # Maximum 30% disk
    
    # Multi-metric composite scoring
    enable_multi_metric: true
    composite_threshold: 0.8                 # Composite score threshold (0-1)
    
    # Metric weights for composite score calculation
    weights:
      system.cpu.utilization: 0.2            # 20% weight
      system.memory.utilization: 0.2         # 20% weight
      process.cpu.utilization: 0.3           # 30% weight
      system.filesystem.utilization: 0.3     # 30% weight
    
    # Anomaly detection configuration
    enable_anomaly_detection: true
    anomaly_history_size: 15                 # Number of historical data points
    anomaly_change_threshold: 50.0           # 50% change triggers anomaly
    anomaly_min_data_points: 3               # Minimum data points before detection
```

### Complete Working Example with Full Pipeline

This example shows ATP integrated with hostmetrics receiver and other processors in a complete OpenTelemetry Collector configuration:

```yaml
receivers:
  otlp:
    protocols:
      grpc:
      http:

  hostmetrics:
    collection_interval: 60s
    scrapers:
      processes:
      process:
        metrics:
          process.cpu.time:
            enabled: true
          process.cpu.utilization:
            enabled: true
          process.memory.usage:
            enabled: true
          process.memory.virtual:
            enabled: true
          process.disk.io:
            enabled: true
          process.threads:
            enabled: true
      cpu:
        metrics:
          system.cpu.time:
            enabled: true
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.usage:
            enabled: true
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.usage:
            enabled: true
          system.filesystem.utilization:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true

processors:
  adaptivetelemetryprocessor:
    # SECURITY: storage_path must be under /var/lib/nrdot-collector/
    storage_path: "/var/lib/nrdot-collector/adaptiveprocess.db"
    retention_minutes: 30
    include_process_list:
      - "/usr/bin/stress-ng"
    
    metric_thresholds:
      system.cpu.utilization: 0.05
      system.memory.utilization: 0.05
      process.cpu.utilization: 0.05
      process.memory.usage: 100
      system.disk.io.read_bytes: 100
      system.network.io.receive_bytes: 100
    
    enable_dynamic_thresholds: true
    dynamic_smoothing_factor: 0.1
    min_thresholds:
      system.cpu.utilization: 0.04
      system.memory.utilization: 0.04
    max_thresholds:
      system.cpu.utilization: 0.30
      system.memory.utilization: 0.30
    
    enable_multi_metric: true
    composite_threshold: 0.8
    weights:
      system.cpu.utilization: 0.2
      system.memory.utilization: 0.2
      process.cpu.utilization: 0.3
      system.filesystem.utilization: 0.3
    
    enable_anomaly_detection: true
    anomaly_history_size: 15
    anomaly_change_threshold: 50.0
    anomaly_min_data_points: 3
  
  memory_limiter:
    check_interval: 1s
    limit_mib: 100
  
  batch:
  
  resourcedetection:
    detectors: ["system"]
    system:
      hostname_sources: ["os"]

exporters:
  otlphttp:
    endpoint: https://otlp.nr-data.net
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}

service:
  pipelines:
    metrics/host:
      receivers: [hostmetrics]
      processors:
        - memory_limiter
        - adaptivetelemetryprocessor
        - resourcedetection
        - batch
      exporters: [otlphttp]
    
    metrics:
      receivers: [otlp]
      processors:
        - adaptivetelemetryprocessor
        - resourcedetection
        - batch
      exporters: [otlphttp]
```

### Kubernetes DaemonSet Configuration

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: monitoring
data:
  collector-config.yaml: |
    receivers:
      hostmetrics:
        collection_interval: 60s
        scrapers:
          cpu:
          memory:
          disk:
          filesystem:
          network:
          process:
    
    processors:
      adaptivetelemetryprocessor:
        # SECURITY: storage_path must be under /var/lib/nrdot-collector/
        storage_path: /var/lib/nrdot-collector/adaptiveprocess.db
        retention_minutes: 30
        include_process_list:
          - "/usr/bin/java"
          - "/usr/sbin/nginx"
        metric_thresholds:
          system.cpu.utilization: 0.05
          system.memory.utilization: 0.05
          process.cpu.utilization: 0.05
        enable_dynamic_thresholds: true
        enable_multi_metric: true
        enable_anomaly_detection: true
      
      resourcedetection:
        detectors: ["env", "system"]
      
      batch:
    
    exporters:
      otlphttp:
        endpoint: https://otlp.nr-data.net
        headers:
          api-key: ${env:NEW_RELIC_LICENSE_KEY}
    
    service:
      pipelines:
        metrics:
          receivers: [hostmetrics]
          processors: [adaptivetelemetryprocessor, resourcedetection, batch]
          exporters: [otlphttp]
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: ghcr.io/newrelic/nrdot-collector:latest
        env:
        - name: NEW_RELIC_LICENSE_KEY
          valueFrom:
            secretKeyRef:
              name: newrelic-license
              key: license-key
        volumeMounts:
        - name: config
          mountPath: /etc/otelcol
        - name: atp-state
          mountPath: /var/lib/nrdot-collector
        - name: hostfs
          mountPath: /hostfs
          readOnly: true
        resources:
          limits:
            memory: 200Mi
            cpu: 200m
          requests:
            memory: 100Mi
            cpu: 100m
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
      - name: atp-state
        hostPath:
          path: /var/lib/nrdot-collector
          type: DirectoryOrCreate
      - name: hostfs
        hostPath:
          path: /
      serviceAccountName: otel-collector
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: monitoring
```

## How It Works

### Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│              Adaptive Telemetry Processor (ATP)                  │
│                                                                  │
│  ┌──────────────┐   ┌─────────────────┐   ┌──────────────────┐ │
│  │   Metric     │──▶│  Threshold      │──▶│  Decision        │ │
│  │  Ingestion   │   │  Evaluation     │   │  Engine          │ │
│  └──────────────┘   └─────────────────┘   └──────────────────┘ │
│                             │                       │            │
│                             ▼                       ▼            │
│                     ┌─────────────────┐    ┌──────────────────┐ │
│                     │ Dynamic         │    │  Anomaly         │ │
│                     │ Thresholds      │    │  Detection       │ │
│                     └─────────────────┘    └──────────────────┘ │
│                             │                       │            │
│                             └───────┬───────────────┘            │
│                                     ▼                            │
│                           ┌──────────────────┐                  │
│                           │  Composite Score │                  │
│                           │  Calculator      │                  │
│                           └──────────────────┘                  │
│                                     │                            │
│                                     ▼                            │
│                           ┌──────────────────┐                  │
│                           │  Filter/Pass     │                  │
│                           │  Decision        │                  │
│                           └──────────────────┘                  │
└─────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
                            JSON File State
             /var/lib/nrdot-collector/adaptiveprocess.db
                  (Historical data, thresholds, baselines)
                  (Secured: Path validation, symlink detection)
```

### Processing Flow

1. **Metric Ingestion**: Receives metrics from hostmetrics or other receivers
2. **Process Filtering**: Checks if metric is from a monitored process (if `include_process_list` configured). If yes, metric is passed immediately.
3. **Threshold Evaluation**: Compares metric value against configured static thresholds
4. **Dynamic Adjustment**: If enabled, adjusts thresholds based on historical baseline using exponential moving average
5. **Composite Scoring**: If enabled, calculates weighted composite score across multiple metrics
6. **Anomaly Detection**: If enabled, detects sudden percentage changes compared to historical data
7. **Pass/Filter Decision**:
   - **Pass**: If process in include list OR metric exceeds threshold OR anomaly detected OR composite score high
   - **Filter**: If process NOT in include list AND metric below threshold AND no anomaly AND composite score low
8. **State Persistence**: Updates JSON file with latest metric values and thresholds
9. **Downstream Emission**: Sends passed metrics to next processor or exporter

### Filtering Logic

ATP uses a multi-layered decision process:

```
For each metric data point:
  ├─ Is process in include_process_list? (if configured)
  │  ├─ YES → PASS metric
  │  └─ NO → Continue
  │
  ├─ Does metric exceed static threshold?
  │  └─ YES → PASS metric
  │
  ├─ Is dynamic thresholds enabled?
  │  ├─ Calculate dynamic threshold from baseline
  │  ├─ Does metric exceed dynamic threshold?
  │  │  └─ YES → PASS metric
  │
  ├─ Is multi-metric scoring enabled?
  │  ├─ Calculate composite score across metrics
  │  ├─ Does composite score exceed threshold?
  │  │  └─ YES → PASS metric
  │
  ├─ Is anomaly detection enabled?
  │  ├─ Calculate % change from historical average
  │  ├─ Does change exceed anomaly threshold?
  │  │  └─ YES → PASS metric (anomaly!)
  │
  └─ All checks failed → DROP metric
```

### State Management

The processor maintains a persistent JSON file containing:
- Historical metric values for baseline calculation
- Dynamic threshold values per metric
- Exponential moving averages for anomaly detection
- Process monitoring state
- Timestamp of last update

**JSON Structure:**

```json
{
  "metrics": {
    "system.cpu.utilization": {
      "history": [0.05, 0.06, 0.04],
      "dynamic_threshold": 0.08,
      "last_updated": 1678900000
    }
  },
  "processes": {
    "nginx": {
      "last_seen": 1678900000,
      "metric_count": 150
    }
  }
}
```

**Retention Policy:**

Data older than `retention_minutes` is automatically purged to prevent file growth:

```
Every collection cycle:
  Remove entries where timestamp < (current_time - retention_minutes * 60)
```

**State File:**
- Location: Configured by `storage_path` (default: `/var/lib/nrdot-collector/adaptiveprocess.db`)
- **Security**: Must be under `/var/lib/nrdot-collector/` - paths outside this directory are rejected
- Format: JSON
- Size: Typically 1-10 MB depending on retention and metric cardinality
- Permissions: Automatically set to `0600` (owner read/write only) for security
- Directory Permissions: Automatically set to `0700` (owner access only)

### Security Features

#### 1. File Permissions
- State file: Should be `0600` (owner read/write only)
- Directory: Should be `0700` (owner access only)
- Prevents unauthorized access to historical metric data

#### 2. Storage Path Validation
- **Restricted directory allowlist**: Storage paths must be under `/var/lib/nrdot-collector/` (no exceptions)
- **Absolute path required**: Relative paths (like `./state.db` or `../data/state.db`) are rejected
- **Symlink protection**: Detects and rejects symlinks in the path to prevent redirection attacks
- **Path traversal prevention**: Uses `filepath.Clean()` to prevent `..` escapes
- **Linux FHS compliant**: Follows Filesystem Hierarchy Standard for application state data
- **Directory permissions**: Creates directories with `0700` (owner-only access)
- **File permissions**: Creates files with `0600` (owner read/write only)

**Allowed paths (examples):**
```yaml
storage_path: "/var/lib/nrdot-collector/state.db"                    # ✅ Allowed
storage_path: "/var/lib/nrdot-collector/data/state.db"               # ✅ Allowed
storage_path: "/var/lib/nrdot-collector/tenant1/process.db"          # ✅ Allowed
```

**Rejected paths (security):**
```yaml
storage_path: "/tmp/state.db"                                         # ❌ Rejected - outside allowed directory
storage_path: "/etc/state.db"                                         # ❌ Rejected - outside allowed directory
storage_path: "./state.db"                                            # ❌ Rejected - relative path
storage_path: "/var/lib/nrdot-collector/../../../tmp/state.db"       # ❌ Rejected - path traversal attempt
```

**Symlink attack prevention:**
```bash
# Attacker attempts to redirect storage to sensitive location:
mkdir -p /var/lib/nrdot-collector/data
ln -s /etc /var/lib/nrdot-collector/data/secrets
# Configuration: storage_path: "/var/lib/nrdot-collector/data/secrets/state.db"
# Result: ❌ Rejected - symlink detected in path
```

This restriction prevents:
- Writing to world-writable directories (like `/tmp`) that could be exploited
- Path traversal attacks trying to escape the allowed directory
- Symlink redirection to sensitive system locations (like `/etc/passwd`)
- User-controlled paths that could access arbitrary filesystem locations

#### 3. Process Path Filtering
- **Full path matching**: Filters by complete executable path (e.g., "/usr/sbin/nginx")
- **Prevents spoofing**: Requires path separator (/ or \) in include list entries
- **Exact match**: Only processes with matching full paths are included

#### 4. Resource Limits
- **Retention limits**: Automatic cleanup of old data prevents disk exhaustion
- **Memory limits**: Use `memory_limiter` processor upstream to prevent OOM

## Performance Considerations

### Resource Usage

| Metric | Typical Value | Notes |
|--------|--------------|-------|
| CPU Usage | < 2% | During steady state |
| Memory Usage | 10-50 MB | Scales with metric cardinality and history size |
| Disk I/O | Low | Periodic JSON file writes |
| State File Size | 1-10 MB | Depends on retention and metric count |
| Network | None | Local-only operations |

### Optimization Tips

1. **Adjust Retention Period**: Shorter retention (15-30 min) reduces state file size
2. **Tune History Size**: Lower `anomaly_history_size` reduces memory usage
3. **Disable Optional Features**: Turn off anomaly detection or dynamic thresholds if not needed
4. **Batch Downstream**: Use `batch` processor after ATP to reduce exporter load
5. **Monitor Storage**: Check `adaptiveprocess.db` file size periodically

### Scalability

- **Metrics Filtered**: Tested with 500+ metrics/second per host
- **Processes Monitored**: Supports 100+ concurrent processes
- **Throughput Impact**: < 5ms latency added to metric pipeline
- **Storage Performance**: Efficient JSON serialization/deserialization

## Example Pipelines

### Scenario 1: Production Web Application

Filter telemetry to only include production Nginx and application servers:

```yaml
receivers:
  otlp:
    protocols:
      grpc:

processors:
  adaptivetelemetry:
    storage_path: /var/lib/nrdot-collector/atp-state
    include_process_list:
      - "/usr/sbin/nginx"
      - "/usr/bin/java"
    
  batch:
    timeout: 10s
    send_batch_size: 1024

exporters:
  otlp/newrelic:
    endpoint: https://otlp.nr-data.net:4317
    headers:
      api-key: ${NEW_RELIC_LICENSE_KEY}

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [adaptivetelemetry, batch]
      exporters: [otlp/newrelic]
    metrics:
      receivers: [otlp]
      processors: [adaptivetelemetry, batch]
      exporters: [otlp/newrelic]
```

### Scenario 2: Multi-Tenant Environment

Isolate telemetry by tenant based on process names:

```yaml
processors:
  adaptivetelemetry/tenant1:
    storage_path: /var/lib/nrdot-collector/atp-tenant1
    include_process_list:
      - "/opt/tenant1/bin/app-tenant1"

  adaptivetelemetry/tenant2:
    storage_path: /var/lib/nrdot-collector/atp-tenant2
    include_process_list:
      - "/opt/tenant2/bin/app-tenant2"

service:
  pipelines:
    traces/tenant1:
      receivers: [otlp]
      processors: [adaptivetelemetry/tenant1, batch]
      exporters: [otlp/newrelic]
    traces/tenant2:
      receivers: [otlp]
      processors: [adaptivetelemetry/tenant2, batch]
      exporters: [otlp/newrelic]
```

## Troubleshooting

### Common Issues

#### Issue: No telemetry passing through processor

**Symptoms**: All telemetry is being dropped

**Solutions**:
1. Verify include_process_list uses full paths with separators (e.g., `/usr/sbin/nginx` not `nginx`)
2. Check executable paths match running processes (use `which <command>` or `readlink -f /proc/<pid>/exe`)
3. Ensure path separators are present - entries without / or \ will not match any process
4. Review collector logs for filtering decisions: `grep "adaptivetelemetry" collector.log`

#### Issue: State file errors

**Symptoms**: `permission denied` or `invalid storage_path` errors

**Solutions**:
1. Verify `storage_path` is under `/var/lib/nrdot-collector/` - paths outside this directory are rejected for security
2. Ensure no symlinks exist in the storage path (use `ls -la` to check)
3. Verify collector has write permissions: `chown -R collector-user:collector-group /var/lib/nrdot-collector/`
4. Check directory permissions are correct: `chmod 700 /var/lib/nrdot-collector/`
5. Check SELinux/AppArmor policies aren't blocking access
6. Delete state file to force recreation: `rm -rf /var/lib/nrdot-collector/*`

#### Issue: High CPU usage

**Symptoms**: Collector CPU usage > 10%

**Solutions**:
1. Check for process churn (many short-lived processes)

### Debug Logging

Enable debug logging to troubleshoot issues:

```yaml
service:
  telemetry:
    logs:
      level: debug
      
processors:
  adaptivetelemetry:
    # ... configuration ...
```

Look for log entries:
- `[adaptivetelemetry] Discovered process: <details>` - Process discovery
- `[adaptivetelemetry] Filtering telemetry from PID <pid>` - Filter decisions
- `[adaptivetelemetry] Enriching telemetry with attributes` - Enrichment actions
- `[adaptivetelemetry] State file saved` - Persistence operations

### Validation Commands

```bash
# Check state file exists and permissions (should be 0600)
ls -la /var/lib/nrdot-collector/

# Verify directory permissions (should be 0700)
stat -c "%a %n" /var/lib/nrdot-collector/

# View state file contents
cat /var/lib/nrdot-collector/adaptiveprocess.db | jq

# Monitor collector logs in real-time
tail -f /var/log/nrdot-collector/collector.log | grep adaptivetelemetry

# List matching processes
ps aux | grep -E "nginx|java|postgres"

# Check process details
ls -l /proc/<pid>/exe
cat /proc/<pid>/cmdline
```

## Security Best Practices

1. **Run with Minimal Privileges**: Use a dedicated service account with only required capabilities
2. **Restrict Storage Path**: Storage paths are automatically restricted to `/var/lib/nrdot-collector/` directory. Do not attempt to use paths outside this directory as they will be rejected. Ensure this directory has proper ownership and permissions (0700).
3. **Audit Access**: Monitor who/what accesses the state directory using filesystem audit tools (auditd, inotify)
4. **Keep Updated**: Apply security patches promptly
5. **Use Full Paths in include_process_list**: Always specify full executable paths (e.g., `/usr/sbin/nginx`) instead of just process names to prevent process name spoofing attacks. See "Process Include List Security" below.
6. **Avoid Symlinks**: Do not use symlinks in the storage path as they are detected and rejected to prevent redirection attacks
7. **Directory Permissions**: The processor automatically creates storage directories with 0700 (owner-only) and files with 0600 (owner read/write only) permissions

### Process Include List Security

The `include_process_list` feature uses **full path matching only** for security.

**Full Path Matching (Required)**
```yaml
include_process_list:
  - "/usr/sbin/nginx"           # Matches only this exact path
  - "/usr/bin/postgres"         # Matches only this exact path
  - "/opt/redis/bin/redis-server"
```

**Security Features:**
- **Prevents process spoofing**: Malicious processes cannot bypass filters by using the same basename
- **Exact path matching**: A process at `/tmp/nginx` will NOT match `/usr/sbin/nginx`
- **Path separator required**: Entries without path separators (/ or \) will not match any process
- **Secure by default**: No basename-only matching to eliminate attack vectors

**Invalid Configuration (Will Not Match):**
```yaml
include_process_list:
  - "nginx"                     # ❌ No path separator - will not match any process
  - "postgres"                  # ❌ No path separator - will not match any process
```

**Attack Scenario Prevented:**
```bash
# An attacker attempts to spoof a trusted process:
cp /malicious/backdoor /tmp/nginx
/tmp/nginx  # ❌ Will NOT match - only "/usr/sbin/nginx" matches

# Valid configuration requires full paths:
include_process_list:
  - "/usr/sbin/nginx"          # ✅ Only matches this exact path
```

**Best Practices:**
- Always use absolute paths with full directory structure
- Verify executable paths using `which <command>` or `readlink -f /proc/<pid>/exe`
- Use Unix paths on Linux/macOS: `/usr/sbin/nginx`
- Use Windows paths on Windows: `C:\Program Files\nginx\nginx.exe`


## Contributing

See [CONTRIBUTING.md](../../CONTRIBUTING.md) for general contribution guidelines.


## Support

- **Issues**: [GitHub Issues](https://github.com/newrelic/nrdot-collector-components/issues)
- **Discussions**: [GitHub Discussions](https://github.com/newrelic/nrdot-collector-components/discussions)
- **Security Issues**: Report to security@newrelic.com
- **Documentation**: [New Relic Docs](https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-introduction/)


## Acknowledgments

- Built on the [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector)
- Inspired by process filtering patterns in observability tools
- Security hardening guided by OWASP and CIS benchmarks

