# Adaptive Telemetry Processor

<!-- status autogenerated section -->
| Status        |           |
| ------------- |-----------|
| Stability     | [development]: traces, metrics, logs |
| Distributions | [nrdot] |
| Issues        | [![Open issues](https://img.shields.io/github/issues-search/newrelic/nrdot-collector-components?query=is%3Aissue%20is%3Aopen%20label%3Aprocessor%2Fadaptivetelemetry%20&label=open&color=orange&logo=opentelemetry)](https://github.com/newrelic/nrdot-collector-components/issues?q=is%3Aopen+is%3Aissue+label%3Aprocessor%2Fadaptivetelemetry) [![Closed issues](https://img.shields.io/github/issues-search/newrelic/nrdot-collector-components?query=is%3Aissue%20is%3Aclosed%20label%3Aprocessor%2Fadaptivetelemetry%20&label=closed&color=blue&logo=opentelemetry)](https://github.com/newrelic/nrdot-collector-components/issues?q=is%3Aclosed+is%3Aissue+label%3Aprocessor%2Fadaptivetelemetry) |
| [Code Owners](https://github.com/newrelic/nrdot-collector-components/blob/main/.github/CODEOWNERS)    | [@your-github-username] |

[development]: https://github.com/open-telemetry/opentelemetry-collector#development
[nrdot]: https://github.com/newrelic/nrdot-collector-releases
<!-- end autogenerated section -->

## Overview

The Adaptive Telemetry Processor (ATP) is an intelligent metric filtering and adaptive sampling component designed for the New Relic OpenTelemetry Collector. It dynamically monitors system and process metrics, filtering out low-value telemetry based on configurable thresholds while maintaining high observability during critical events. ATP reduces telemetry costs by up to 70% while preserving visibility into performance anomalies.

### Key Features

- **Metric Threshold Filtering**: Filters metrics based on configurable thresholds for CPU, memory, disk, and network
- **Process-Based Sampling**: Monitors specific processes by name (e.g., `nginx`, `java`, `stress-ng`)
- **Dynamic Threshold Adjustment**: Automatically adapts thresholds based on historical baselines and workload patterns
- **Multi-Metric Composite Scoring**: Combines multiple metrics with configurable weights for holistic health assessment
- **Anomaly Detection**: Detects sudden metric changes and ensures anomalous data is always captured
- **Stateful Processing**: Maintains persistent state in JSON file across collector restarts
- **Low Overhead**: Minimal performance impact with efficient metric evaluation

### Use Cases

- **Cost Optimization**: Reduce telemetry volume by 50-70% by filtering "normal" metrics while preserving anomalies
- **Noise Reduction**: Eliminate low-value metrics from idle or baseline systems
- **Selective Monitoring**: Monitor only specific processes (applications, containers, services)
- **Dynamic Environments**: Adapt to changing workload patterns in containerized or cloud environments
- **Performance Troubleshooting**: Automatically increase sampling during performance degradation
- **Compliance & Auditing**: Maintain complete audit trail during critical events while reducing steady-state data

## Configuration

### Basic Configuration

```yaml
processors:
  adaptivetelemetryprocessor:
    # Storage configuration for persistence (JSON file)
    storage_path: "./adaptiveprocess.db"
    
    # Data retention period in minutes
    retention_minutes: 30
    
    # Process list to monitor (process names only)
    include_process_list:
      - "nginx"
      - "java"
      - "postgres"
    
    # Metric thresholds - metrics below these values are filtered out
    metric_thresholds:
      # CPU metrics (utilization is 0-1 scale, time in seconds)
      system.cpu.utilization: 0.05           # 5% CPU utilization
      system.cpu.time: 5.0                   # 5 seconds CPU time
      
      # Memory metrics (utilization 0-1 scale, usage in bytes)
      system.memory.utilization: 0.05        # 5% memory utilization
      system.memory.usage: 104857600         # 100 MB
      
      # Process-specific metrics
      process.cpu.utilization: 0.05          # 5% process CPU
      process.memory.usage: 104857600        # 100 MB process memory
      
      # Disk metrics
      system.disk.io: 1048576                # 1 MB disk I/O
      system.filesystem.utilization: 0.05    # 5% disk utilization
      
      # Network metrics
      system.network.io: 1048576             # 1 MB network I/O
```

### Advanced Configuration

```yaml
processors:
  adaptivetelemetryprocessor:
    # Storage configuration
    storage_path: "./adaptiveprocess.db"
    retention_minutes: 30
    
    # Process filtering - monitor specific processes by name
    include_process_list:
      - "stress-ng"
      - "nginx"
      - "java"
      - "postgres"
    
    # Static metric thresholds - metrics below these values are filtered
    metric_thresholds:
      # CPU metrics from hostmetrics receiver
      system.cpu.utilization: 0.05           # 5% CPU utilization (0-1 scale)
      system.cpu.time: 5.0                   # CPU time in seconds
      
      # Memory metrics from hostmetrics receiver
      system.memory.utilization: 0.05        # 5% memory utilization (0-1 scale)
      system.memory.usage: 100               # in bytes (minimal for testing)
      
      # Process metrics from hostmetrics receiver
      process.cpu.utilization: 0.05          # 5% process CPU (0-1 scale)
      process.memory.usage: 100              # process memory in bytes
      process.memory.virtual: 100            # virtual memory in bytes
      
      # Disk metrics from hostmetrics receiver
      system.disk.io.read_bytes: 100         # 100B disk read
      system.disk.io.write_bytes: 100        # 100B disk write
      system.filesystem.utilization: 0.05    # 5% disk utilization (0-1 scale)
      
      # Network metrics from hostmetrics receiver
      system.network.io.receive_bytes: 100   # 100B network receive
      system.network.io.transmit_bytes: 100  # 100B network transmit
    
    # Dynamic threshold configuration
    enable_dynamic_thresholds: true
    dynamic_smoothing_factor: 0.1            # Exponential moving average smoothing
    
    # Minimum thresholds (dynamic thresholds cannot go below these)
    min_thresholds:
      system.cpu.utilization: 0.04           # Minimum 4% CPU
      system.memory.utilization: 0.04        # Minimum 4% memory
      process.cpu.utilization: 0.04          # Minimum 4% process CPU
      system.filesystem.utilization: 0.04    # Minimum 4% disk
    
    # Maximum thresholds (dynamic thresholds cannot exceed these)
    max_thresholds:
      system.cpu.utilization: 0.30           # Maximum 30% CPU
      system.memory.utilization: 0.30        # Maximum 30% memory
      process.cpu.utilization: 0.30          # Maximum 30% process CPU
      system.filesystem.utilization: 0.30    # Maximum 30% disk
    
    # Multi-metric composite scoring
    enable_multi_metric: true
    composite_threshold: 0.8                 # Composite score threshold (0-1)
    
    # Metric weights for composite score calculation
    weights:
      system.cpu.utilization: 0.2            # 20% weight
      system.memory.utilization: 0.2         # 20% weight
      process.cpu.utilization: 0.3           # 30% weight
      system.filesystem.utilization: 0.3     # 30% weight
    
    # Anomaly detection configuration
    enable_anomaly_detection: true
    anomaly_history_size: 15                 # Number of historical data points
    anomaly_change_threshold: 50.0           # 50% change triggers anomaly
    anomaly_min_data_points: 3               # Minimum data points before detection
```

### Complete Working Example with Full Pipeline

This example shows ATP integrated with hostmetrics receiver and other processors in a complete OpenTelemetry Collector configuration:

```yaml
receivers:
  otlp:
    protocols:
      grpc:
      http:

  hostmetrics:
    collection_interval: 60s
    scrapers:
      processes:
      process:
        metrics:
          process.cpu.time:
            enabled: true
          process.cpu.utilization:
            enabled: true
          process.memory.usage:
            enabled: true
          process.memory.virtual:
            enabled: true
          process.disk.io:
            enabled: true
          process.threads:
            enabled: true
      cpu:
        metrics:
          system.cpu.time:
            enabled: true
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.usage:
            enabled: true
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
      filesystem:
        metrics:
          system.filesystem.usage:
            enabled: true
          system.filesystem.utilization:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true

processors:
  adaptivetelemetryprocessor:
    storage_path: "./adaptiveprocess.db"
    retention_minutes: 30
    include_process_list:
      - "stress-ng"
    
    metric_thresholds:
      system.cpu.utilization: 0.05
      system.memory.utilization: 0.05
      process.cpu.utilization: 0.05
      process.memory.usage: 100
      system.disk.io.read_bytes: 100
      system.network.io.receive_bytes: 100
    
    enable_dynamic_thresholds: true
    dynamic_smoothing_factor: 0.1
    min_thresholds:
      system.cpu.utilization: 0.04
      system.memory.utilization: 0.04
    max_thresholds:
      system.cpu.utilization: 0.30
      system.memory.utilization: 0.30
    
    enable_multi_metric: true
    composite_threshold: 0.8
    weights:
      system.cpu.utilization: 0.2
      system.memory.utilization: 0.2
      process.cpu.utilization: 0.3
      system.filesystem.utilization: 0.3
    
    enable_anomaly_detection: true
    anomaly_history_size: 15
    anomaly_change_threshold: 50.0
    anomaly_min_data_points: 3
  
  memory_limiter:
    check_interval: 1s
    limit_mib: 100
  
  batch:
  
  resourcedetection:
    detectors: ["system"]
    system:
      hostname_sources: ["os"]

exporters:
  otlphttp:
    endpoint: https://otlp.nr-data.net
    headers:
      api-key: ${env:NEW_RELIC_LICENSE_KEY}

service:
  pipelines:
    metrics/host:
      receivers: [hostmetrics]
      processors:
        - memory_limiter
        - adaptivetelemetryprocessor
        - resourcedetection
        - batch
      exporters: [otlphttp]
    
    metrics:
      receivers: [otlp]
      processors:
        - adaptivetelemetryprocessor
        - resourcedetection
        - batch
      exporters: [otlphttp]
```

### Kubernetes DaemonSet Configuration

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: monitoring
data:
  collector-config.yaml: |
    receivers:
      hostmetrics:
        collection_interval: 60s
        scrapers:
          cpu:
          memory:
          disk:
          filesystem:
          network:
          process:
    
    processors:
      adaptivetelemetryprocessor:
        storage_path: /var/lib/atp/adaptiveprocess.db
        retention_minutes: 30
        include_process_list:
          - "java"
          - "nginx"
        metric_thresholds:
          system.cpu.utilization: 0.05
          system.memory.utilization: 0.05
          process.cpu.utilization: 0.05
        enable_dynamic_thresholds: true
        enable_multi_metric: true
        enable_anomaly_detection: true
      
      resourcedetection:
        detectors: ["env", "system"]
      
      batch:
    
    exporters:
      otlphttp:
        endpoint: https://otlp.nr-data.net
        headers:
          api-key: ${env:NEW_RELIC_LICENSE_KEY}
    
    service:
      pipelines:
        metrics:
          receivers: [hostmetrics]
          processors: [adaptivetelemetryprocessor, resourcedetection, batch]
          exporters: [otlphttp]
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otel-collector
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: otel-collector
  template:
    metadata:
      labels:
        app: otel-collector
    spec:
      containers:
      - name: otel-collector
        image: ghcr.io/newrelic/nrdot-collector:latest
        env:
        - name: NEW_RELIC_LICENSE_KEY
          valueFrom:
            secretKeyRef:
              name: newrelic-license
              key: license-key
        volumeMounts:
        - name: config
          mountPath: /etc/otelcol
        - name: atp-state
          mountPath: /var/lib/atp
        - name: hostfs
          mountPath: /hostfs
          readOnly: true
        resources:
          limits:
            memory: 200Mi
            cpu: 200m
          requests:
            memory: 100Mi
            cpu: 100m
      volumes:
      - name: config
        configMap:
          name: otel-collector-config
      - name: atp-state
        hostPath:
          path: /var/lib/otel-atp
          type: DirectoryOrCreate
      - name: hostfs
        hostPath:
          path: /
      serviceAccountName: otel-collector
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: monitoring
```

## How It Works

### Architecture

```
┌─────────────────────────────────────────────────────────────────┐
│              Adaptive Telemetry Processor (ATP)                  │
│                                                                  │
│  ┌──────────────┐   ┌─────────────────┐   ┌──────────────────┐ │
│  │   Metric     │──▶│  Threshold      │──▶│  Decision        │ │
│  │  Ingestion   │   │  Evaluation     │   │  Engine          │ │
│  └──────────────┘   └─────────────────┘   └──────────────────┘ │
│                             │                       │            │
│                             ▼                       ▼            │
│                     ┌─────────────────┐    ┌──────────────────┐ │
│                     │ Dynamic         │    │  Anomaly         │ │
│                     │ Thresholds      │    │  Detection       │ │
│                     └─────────────────┘    └──────────────────┘ │
│                             │                       │            │
│                             └───────┬───────────────┘            │
│                                     ▼                            │
│                           ┌──────────────────┐                  │
│                           │  Composite Score │                  │
│                           │  Calculator      │                  │
│                           └──────────────────┘                  │
│                                     │                            │
│                                     ▼                            │
│                           ┌──────────────────┐                  │
│                           │  Filter/Pass     │                  │
│                           │  Decision        │                  │
│                           └──────────────────┘                  │
└─────────────────────────────────────────────────────────────────┘
                                     │
                                     ▼
                            JSON File State
                      ./adaptiveprocess.db
                  (Historical data, thresholds, baselines)
```

### Processing Flow

1. **Metric Ingestion**: Receives metrics from hostmetrics or other receivers
2. **Process Filtering**: Checks if metric is from a monitored process (if `include_process_list` configured). If yes, metric is passed immediately.
3. **Threshold Evaluation**: Compares metric value against configured static thresholds
4. **Dynamic Adjustment**: If enabled, adjusts thresholds based on historical baseline using exponential moving average
5. **Composite Scoring**: If enabled, calculates weighted composite score across multiple metrics
6. **Anomaly Detection**: If enabled, detects sudden percentage changes compared to historical data
7. **Pass/Filter Decision**:
   - **Pass**: If process in include list OR metric exceeds threshold OR anomaly detected OR composite score high
   - **Filter**: If process NOT in include list AND metric below threshold AND no anomaly AND composite score low
8. **State Persistence**: Updates JSON file with latest metric values and thresholds
9. **Downstream Emission**: Sends passed metrics to next processor or exporter

### Filtering Logic

ATP uses a multi-layered decision process:

```
For each metric data point:
  ├─ Is process in include_process_list? (if configured)
  │  ├─ YES → PASS metric
  │  └─ NO → Continue
  │
  ├─ Does metric exceed static threshold?
  │  └─ YES → PASS metric
  │
  ├─ Is dynamic thresholds enabled?
  │  ├─ Calculate dynamic threshold from baseline
  │  ├─ Does metric exceed dynamic threshold?
  │  │  └─ YES → PASS metric
  │
  ├─ Is multi-metric scoring enabled?
  │  ├─ Calculate composite score across metrics
  │  ├─ Does composite score exceed threshold?
  │  │  └─ YES → PASS metric
  │
  ├─ Is anomaly detection enabled?
  │  ├─ Calculate % change from historical average
  │  ├─ Does change exceed anomaly threshold?
  │  │  └─ YES → PASS metric (anomaly!)
  │
  └─ All checks failed → DROP metric
```

### State Management

The processor maintains a persistent JSON file containing:
- Historical metric values for baseline calculation
- Dynamic threshold values per metric
- Exponential moving averages for anomaly detection
- Process monitoring state
- Timestamp of last update

**JSON Structure:**

```json
{
  "metrics": {
    "system.cpu.utilization": {
      "history": [0.05, 0.06, 0.04],
      "dynamic_threshold": 0.08,
      "last_updated": 1678900000
    }
  },
  "processes": {
    "nginx": {
      "last_seen": 1678900000,
      "metric_count": 150
    }
  }
}
```

**Retention Policy:**

Data older than `retention_minutes` is automatically purged to prevent file growth:

```
Every collection cycle:
  Remove entries where timestamp < (current_time - retention_minutes * 60)
```

**State File:**
- Location: Configured by `storage_path` (default: `./adaptiveprocess.db`)
- Format: JSON
- Size: Typically 1-10 MB depending on retention and metric cardinality
- Permissions: Should be `0600` (owner read/write only) for security

### Security Features

#### 1. File Permissions
- State file: Should be `0600` (owner read/write only)
- Directory: Should be `0700` (owner access only)
- Prevents unauthorized access to historical metric data

#### 2. Storage Path Validation
- **Path sanitization**: Validates storage path before writing
- **Directory creation**: Ensures directory exists with correct permissions

#### 3. Process Name Filtering
- **Simple string matching**: Filters by process basename (e.g., "nginx", "java")
- **Exact match**: Required for process names in include list

#### 4. Resource Limits
- **Retention limits**: Automatic cleanup of old data prevents disk exhaustion
- **Memory limits**: Use `memory_limiter` processor upstream to prevent OOM

## Performance Considerations

### Resource Usage

| Metric | Typical Value | Notes |
|--------|--------------|-------|
| CPU Usage | < 2% | During steady state |
| Memory Usage | 10-50 MB | Scales with metric cardinality and history size |
| Disk I/O | Low | Periodic JSON file writes |
| State File Size | 1-10 MB | Depends on retention and metric count |
| Network | None | Local-only operations |

### Optimization Tips

1. **Adjust Retention Period**: Shorter retention (15-30 min) reduces state file size
2. **Tune History Size**: Lower `anomaly_history_size` reduces memory usage
3. **Disable Optional Features**: Turn off anomaly detection or dynamic thresholds if not needed
4. **Batch Downstream**: Use `batch` processor after ATP to reduce exporter load
5. **Monitor Storage**: Check `adaptiveprocess.db` file size periodically

### Scalability

- **Metrics Filtered**: Tested with 500+ metrics/second per host
- **Processes Monitored**: Supports 100+ concurrent processes
- **Throughput Impact**: < 5ms latency added to metric pipeline
- **Storage Performance**: Efficient JSON serialization/deserialization

## Example Pipelines

### Scenario 1: Production Web Application

Filter telemetry to only include production Nginx and application servers:

```yaml
receivers:
  otlp:
    protocols:
      grpc:

processors:
  adaptivetelemetry:
    storage_path: /var/lib/nrdot-collector/atp-state
    include_process_list:
      - "nginx"
      - "java"
    
  batch:
    timeout: 10s
    send_batch_size: 1024

exporters:
  otlp/newrelic:
    endpoint: https://otlp.nr-data.net:4317
    headers:
      api-key: ${NEW_RELIC_LICENSE_KEY}

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [adaptivetelemetry, batch]
      exporters: [otlp/newrelic]
    metrics:
      receivers: [otlp]
      processors: [adaptivetelemetry, batch]
      exporters: [otlp/newrelic]
```

### Scenario 2: Multi-Tenant Environment

Isolate telemetry by tenant based on process names:

```yaml
processors:
  adaptivetelemetry/tenant1:
    storage_path: /var/lib/nrdot-collector/atp-tenant1
    include_process_list:
      - "app-tenant1"
  
  adaptivetelemetry/tenant2:
    storage_path: /var/lib/nrdot-collector/atp-tenant2
    include_process_list:
      - "app-tenant2"

service:
  pipelines:
    traces/tenant1:
      receivers: [otlp]
      processors: [adaptivetelemetry/tenant1, batch]
      exporters: [otlp/newrelic]
    traces/tenant2:
      receivers: [otlp]
      processors: [adaptivetelemetry/tenant2, batch]
      exporters: [otlp/newrelic]
```

## Troubleshooting

### Common Issues

#### Issue: No telemetry passing through processor

**Symptoms**: All telemetry is being dropped

**Solutions**:
1. Check process list configuration matches actual running processes
2. Verify full executable paths are correct (use `which <command>` or `readlink -f /proc/<pid>/exe`)
3. Check UIDs match (use `ps aux | grep <process>` to see UID)
4. Review collector logs for filtering decisions: `grep "adaptivetelemetry" collector.log`

#### Issue: State file errors

**Symptoms**: `permission denied`

**Solutions**:
1. Verify collector has write permissions to storage_path
2. Check SELinux/AppArmor policies aren't blocking access
3. Delete state file to force recreation: `rm -rf /var/lib/nrdot-collector/atp-state/*`

#### Issue: High CPU usage

**Symptoms**: Collector CPU usage > 10%

**Solutions**:
1. Check for process churn (many short-lived processes)

### Debug Logging

Enable debug logging to troubleshoot issues:

```yaml
service:
  telemetry:
    logs:
      level: debug
      
processors:
  adaptivetelemetry:
    # ... configuration ...
```

Look for log entries:
- `[adaptivetelemetry] Discovered process: <details>` - Process discovery
- `[adaptivetelemetry] Filtering telemetry from PID <pid>` - Filter decisions
- `[adaptivetelemetry] Enriching telemetry with attributes` - Enrichment actions
- `[adaptivetelemetry] State file saved` - Persistence operations

### Validation Commands

```bash
# Check state file exists and permissions
ls -la /var/lib/nrdot-collector/atp-state/

# View state file contents (if not encrypted)
cat /var/lib/nrdot-collector/atp-state/state.json | jq

# Monitor collector logs in real-time
tail -f /var/log/nrdot-collector/collector.log | grep adaptivetelemetry

# List matching processes
ps aux | grep -E "nginx|java|postgres"

# Check process details
ls -l /proc/<pid>/exe
cat /proc/<pid>/cmdline
```

## Security Best Practices

1. **Run with Minimal Privileges**: Use a dedicated service account with only required capabilities
2. **Restrict Storage Path**: Configure `storage_path` to a secure location
3. **Audit Access**: Monitor who/what accesses the state directory
4. **Keep Updated**: Apply security patches promptly

## Compatibility

- **OpenTelemetry Collector**: v0.90.0+
- **Go Version**: 1.21+
- **Operating Systems**:
   - Linux: Full support (Ubuntu 20.04+, RHEL 8+, Amazon Linux 2)
   - macOS: Development/testing only
   - Windows: Not currently supported
- **Container Platforms**:
   - Docker
   - Kubernetes (DaemonSet deployment recommended)
   - ECS/EKS
   - OpenShift

## Contributing

See [CONTRIBUTING.md](../../CONTRIBUTING.md) for general contribution guidelines.

### Component-Specific Guidelines

When contributing to the Adaptive Telemetry Processor:

1. **Security First**: All changes must maintain or improve security posture
2. **Test Coverage**: Maintain >80% code coverage with unit tests
3. **Performance**: Benchmark changes with `make benchmark`
4. **Documentation**: Update this README and inline code documentation
5. **Backwards Compatibility**: Follow semantic versioning for configuration changes


## Support

- **Issues**: [GitHub Issues](https://github.com/newrelic/nrdot-collector-components/issues)
- **Discussions**: [GitHub Discussions](https://github.com/newrelic/nrdot-collector-components/discussions)
- **Security Issues**: Report to security@newrelic.com
- **Documentation**: [New Relic Docs](https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-introduction/)


## Acknowledgments

- Built on the [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector)
- Inspired by process filtering patterns in observability tools
- Security hardening guided by OWASP and CIS benchmarks

